#### зачем вообще написана эта статья

Это обзор наиболее важных по моему мнению статьях  о сегментации и классификации точек в Point Cloud (данные
 получаемые с лидаров) за последние несколько лет. Я не профессионал работающий в этой области уже несколько лет, 
 просто некоторое время нахад мне потребовалось решить эту задачу и я делала ислледование существующих 
 методов. Здесь вы можете его найти. Для каждой статья выписана следующая информация: какая задача решается
 в статье, как её решают, картинки из статьи с моделью и описанием, ссылка на код, если он был найден.

Эта статья будет полезна тем, кто хорошо знаком с нейроннами сетями, в особенности со сверточными, и хочет понять, 
как применять свертки к неструктурированным данным (к примеру графам). Я собирала эту информацию для себя и верю, 
что она может быть кому-то полезна.

!! картинку с решаемой хадачей. к примеру семантическая сементация комнаты

#### существующие датасеты

Для начала - какие данные есть в открытом доступе.
* [китти](http://www.cvlibs.net/datasets/kitti/) - датасет собирался беспилотных автомобилей. Данные с лидаров и
 изображения с камер установленных на крыше автомобиля. Предполагаетсяя решать задачи детекции, классификации и 
 отслеживания участников дорожного движения.
* [Stanford Large-Scale 3DIndoor Spaces Dataset (S3DIS)](http://buildingparser.stanford.edu/dataset.html) - размеченные
 сцены внутри зданий
* [ScanNet](http://www.scan-net.org/) - размеченные сцены внутри зданий
* [NYUV2](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html) - размеченные сцены внутри зданий
* [ShapeNet](https://www.shapenet.org/) - объекты разных форм
* [ModelNet40](http://modelnet.cs.princeton.edu/) - объекты разных форм
* [SHREC15](https://www.cs.cf.ac.uk/shaperetrieval/shrec15/index.html) - разные позы животных и человека

#### особенности работы с облаками точек
Нейронные сети пришли в эту область совсем недавно. И стандартные архитектуры вроед плносвязных, сверточных сетей 
не применимы для решения этой задачи. Почему? Рассмотрим вначале несколько свойст 3d объекта, состоящего из множества 
точек.

1. Данные не структурированы. Наш объект - это точки без какого-то порядка. Нсли на изображения у каждого пикселя есть 
 своё место, тут мы можем спокойно перемешать точки и объект не измениться. При мерестановке пикселей мы наоборот
  получим абсолютно новую картинку. 
2. Взаимодействие между точка объекта. Они имеют связи друг с другом так же как и соседние пиксели на изображении.
3. инвариантность к преобразованиям. Если мы изменим систему координат, объект не изменится. То есть алгоритм должен 
распозновать объект в различных системах координат. 

Основную проблему для стандортных нейронных сетей создает пункт 1 - Стандартные нейронные сети очень зависимы от 
порядкового номера признака.

А теперь разберемся, как же нейронные сети решают задачи 

#### Наиболее важные статьи за последние 3 года
Нейронных сетей, которыми пользуюся в качестве основы все остальные исследователи не так уж и много. Я выделила три 
архитектуры, о которых необходимо иметь представление каждому, кто собирается работать с неструктурированными данными:
* PointNet
* PointNet++
* DGCNN

 *  [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)
    * что решают:  Задачи классификации и сегментации в point clouds. Первопроходцы в работе с неструктурированными 
    данными.
    * как решают: Одна сеть с двумя головами. Модель состоит из следующих блоков:
      * сеть для определения преобразования, которое потом применится ко всем точкам, 
      * преобразованте, применяемое к каждой точке по отдельности (обычный персепторн)
      * maxpooling, который объединяет информацию с разных точек и создает глобальный вектор признаков для всего объекта.
      * далее сеть делится на две части: 
        1. сеть для классификации: глобальный вектор признаков идет на вход полносвязной сети для определения 
      класса объекта
        2. сеть для сегментации: глобальные вектор после макс пулинга и подсчитанные признаки для каждой точки идут на 
        вход сети, которая определяем класс для каждой точки. 

![архитектура PointNet](https://habrastorage.org/webt/fu/pv/wi/fupvwi8uf8d2pcvxbvh9ahttf5s.png)
    * [код](https://github.com/charlesq34/pointnet)

* [PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://arxiv.org/abs/1706.02413)
  * что решают: Задачи классификации и сегментации в point clouds. Те же ребята из Стенфорда, что описали PointNet.
  * как решают: рекурсивно применяют pointNet к более мелким подоблакам, по аналогии со сверточными сетями.
   Это позволяет выделить локальные признаки, которые терялись.
   
![архитектура PointNet++](https://habrastorage.org/webt/py/pj/it/pypjitwxitebw0losh7ucvr43fu.png)
  * [код](https://github.com/charlesq34/pointnet2)
  
 * [Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829)
   * что решают: Задачи классификации и сегментации в point clouds. 
   * как решают: на основе имеющихся точек строя граф: вершины - точки, ребра существуют только между k ближайшими 
   точками. Далее определяет Edge conv - специальную свертку ребрах исходящих из текущей точки. В статье предложено
    несколько вариантов этой свертки. В результате они использовали следующий: для каждой точки $x_i$ по все её 
    J соседним точкам считали M признаков $x_{i,m} = max_j (Relu (\pci_m * (x_i - x_j) + \phi*x_i ))$. 
    Полученное значение запоминается, как новый эмбединг точки. Обращаю внимание, что здесь используются локальные и 
    глобальные координаты как входные данные для свертки. 
    \
    \
    Если у нас определена светка на графе - мы можем просто построить сверточную сеть, что здесь и cделано. 
    Также можно заметить подсчет преобразований и применения их к каждой точке по аналогии с PointNet
    \
    В этой статье вы также нейдете прекрасный обзор других методов решения.
    
![архитектура DGCNN](https://habrastorage.org/webt/0w/lp/hm/0wlphmzbejgym-a_suxjd38tea4.png)
   * [код](https://github.com/WangYueFt/dgcnn)
   
Статьи на основе PointNet и PointNet++:
 * [PointWise: An Unsupervised Point-wise Feature Learning Network](https://arxiv.org/abs/1901.04544)
   * что решают: задачу сегментации без учителя
   * особенности: обучение без учителя
   * как решают: обучают вектор ембедингов для каждой точки. С помощью этих эмбедингов можно кластеризовать объекты.
    Похожие объекты должны иметь похожие эмбединги (например дне ножки стула), несмотря на их удаленность. В качестве 
    модели используют PointNet. Основное новшество - функция ошибки, она состоит из ошибки реконструкции и ошибки 
    гладкости. 
    Ошибка реконструкции использует информацию о контексте точки для того, чтобы точки, которые окружены одинаковым
     геометрическим контекстом, имели похожии эмбединги. Для её подсчета на основе вектора эмбедингов для одной точки 
     генерируются новые точки около нее. То есть признаковое описание точки должно содержать информацию об форме 
     объекта вокруг точки.Дальше просто смотрим, насколько сгенерированные точки выпадают из реальной формы объекта:
     L_{reconst} = \sum_{x \in Rec(f_{i,j})} \min_{y \in Env(p_{i,j})} ||x-y||_2^2 + \sum_{y \in Env(p_{i,j})} \min_{x \in Rec(f_{i,j})} ||x-y||_2^2
    Ошибка гладкости нужна для того, чтобы ембединги были похожими у лежащих рядом точек и непохожими у далеких точек.
     Тут самое прекрасное - то что они измеряют близость не просто как норму между двумя точка в увклидовом пространсте
     ,а растояние через пространство объекта. Для каждой точки выбирается одна точка из k ближайщих и из k дальнейших. 
     Текущий эмбединнг должен быть ближе к ближайще минимум на некий margin чем до дальнейшей.

 * [PointCNN: Convolution On X-Transformed Points](https://papers.nips.cc/paper/7362-pointcnn-convolution-on-x-transformed-points)
   * что решают: задачу сегментации и классификации
   * как решают: как я поняла (вот здесь за правильность не ручаюсь)  реализовали новую свертку. 
   1 Переводят координаты ближайщих точек к нашей в локальные координаты. 
   2. Далее считают фичи как в pointNet 
   3. Используя локальные координаты считают X-матрицу преобразования координат, применяют её к подсчитанным
    объединению подсчитанных признаков и изначальных, например цвет или нормаль к поверхности. Просто переводят 
    признаки в другую систему координат. 4. применяют в точкам свертки. Важно отметить, что от места порядка точек 
    здесь много зависит и после их перемешивания результат будет другим.
  ![архитектура PointCNN](https://habrastorage.org/webt/q5/j6/vb/q5j6vblmeheg-oq0lx5efjicf0w.png)
  ![архитектура PointCNN](https://habrastorage.org/webt/q9/zq/pg/q9zqpgmuc-86hnxedvjfaotzkrq.png)
  ![архитектура PointCNN](https://habrastorage.org/webt/gl/vy/w8/glvyw878vel074w3bt8cq4vgsok.png)

   * [код](https://github.com/yangyanli/PointCNN)
    
 * [SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation](https://arxiv.org/abs/1711.08588)
   * что решают: задачу сегментации
   * как решают: В качестве основы - PointNet, вначале считаем вектор признаков для каждой точки в отдельности. 
   Далее на основе этих точек считаем 3 матрицы (похожести, уверенности и сегментации)
   Ошибка обучения будет сумируется из 3ех ошибок, подсчитанных по матрицам соответсветно: $L = L_{SIM} + L_{CF} + L_{SEM}$    
   Матрица похожести квадратная размером количество точек* количество точек. Элемент на пересечении iой строки и jго 
   столбца говорит о том, принадлежат ли эти точки одному объекту или нет. Точки принадлежащие одному объекту должны
   иметь похожие вектора. Елементы матрицы могут принимать одно из 3ех значений: точки i и j  принадлежат одному 
   объекту, точки принадлежат одному классу объектов, но разным объектам (и то и то стул, но стулья разные), или это
   вообще точки из разных сущностей.
   Ошибка похожести, которая считается по этой матрице зависит от истинного значения, которое должно было бать в ней.
   Если точки из одного объекта - ошибка равна разнице векторов точек; если один класс объектов - 0 или константа
   минус разница векторов объектов, умноженная; если это разные объекты - то же самое , только другая константа.
        \[ l(i,j) = \begin{cases} 
        $||F_{sim_i}-F_{sim_j}||_2$ & C_{i,j} == 1 \\
        $\alpha \max (0, K_1 - ||F_{sim_i}-F_{sim_j}||_2)$ & C_{i,j} == 2 \\
        $\max (0, K_2 - ||F_{sim_i}-F_{sim_j}||_2)$ & C_{i,j} == 2\end{cases} \]
      Матрица уверенности - это вектор длинной равной количесву точек. Для каждой точки мы считаем пересечение деленное
       на объединение (intersection over union - IoU) между множество точек, которые принадлежат объекту согласно 
       работе нашего алгоритма, и множеством точек, которые в реальности принадлежат объекту с нашей точкой. Ошибка - 
       просто L2 между правдой и подсчитанной матрицей
        
        Матрица сегментации имеет размеры - количество точек*количество классов. Матрица сегментации считается 
        отдельной "головой" сети и это её конечный результат. Ошибка здесь счиьается как кроссвалидация.
   * [код](https://github.com/laughtervv/SGPN)
    
 * [Know What Your Neighbors Do:3D Semantic Segmentation of Point Clouds](https://arxiv.org/abs/1810.01151)
   * что решают: задачу сегментации
   * как решают: Вначале долго считают признаки, сложнее чем в PointNet, с кучей residual связей, и сумм, но в общем и целом - то же самое. Основное отличие  - они паралельно считают локальные и глобальные признаки для каждой точки. Потом берут k ближайщих точек к нашей и делают из них матрицу признаков размера: количество точек * k * количество признаков после последнего слоя сети, которая считает признаки. Далее применяют ко все соседям одной точки свертки, пуллинг и получают вектор признаков для этой точки. По этому признаку сеть делает предсказание - а к какому класу относится точка.
        
        Ошибка тут не стандартная кроссэнтропия, тут считаются две ошибки: 1. pairwise distance loss - точки из одного класса должны быть ближе чем $\tau_{near}$ и точки из разных классов должны быть дольше чем $\tau_{far}$. 2.  centroid loss - точки из одноко класса должны быть близки друг к другу
        \[ l(i,j) = \begin{cases} 
        $max(||x_i-x_j|| - \tau_{near}, 0) & C_i==C_j$ \\
        $max(\tau_{far} - ||x_i-x_j||, 0) & C_i==C_j$\end{cases} \]
        
        
статьи на основе DGCNN:
 * [Linked Dynamic Graph CNN: Learning on Point Cloud via Linking Hierarchical Featurese](https://arxiv.org/abs/1904.10014)
   * что решают: Задачи классификации и сегментации в point clouds. 
   * как решают: использовали предыдущую архитектуру и добавили в неё residual connections
 ![архитектура Linked DGCNN](https://habrastorage.org/webt/ov/zk/h7/ovzkh78zz0cnczzdp0notx8u6ea.png)

 * [SpiderCNN: Deep Learning on Point Sets with Parameterized Convolutional Filters](https://arxiv.org/abs/1803.11527)
   * что решают: задачи сегментации и классификации
   * как решают: по аналогии с DGCNN применяют аналог сверток к k ближайщим точкам около текущей, предварительно отсортировав. Основное отличие - вместно обычных координа на вход свертке подается подобие разложения функции тейлора $f_{w^T}(x,y,z) = w_0^T+w_1^Tx+w_2^Ty+w_3^Tz+w_4^Txy+w_5^Tyz+w_6^Txz+w_7^Txyz$.
![архитектура SpiderCNN](https://habrastorage.org/webt/i4/by/ri/i4byrilcta4j39uxxevtacr9q1g.png)
   * [код](https://github.com/xyf513/SpiderCNN)

 * SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud \cite{wu2018squeezeseg}
   * что решают: задачи сегментации и классификации
   * как решают: вначале переводят облако точек в сферические координаты, потом сжимают эту сферу до пяти изображений. Далее боле-менее обычная сверточная сеть для сегментации в виде автоэнкодера.
![архитектура SqueezeSeg](https://habrastorage.org/webt/jy/tv/rq/jytvrqjp9h7hqyyqgrk4mbt0kt4.png)
   * [код](https://github.com/BichenWuUCB/SqueezeSeg)

