#### Введение

Некоторое время назад мне потребовалось решить задачу классификации и сегментации точек в Point Cloud (данные, полученные с лидаров). После провальных поисков какого-то общего обзора существующих методов, было решено его сделать. Результат вы можете видеть: здесь собраны наиболее важные и интересные статьи по этой теме за последние несколько лет (по моему мнению). 

Эта статья будет полезна тем, кто хорошо знаком с нейронными сетями, в особенности со сверточными, и хочет понять, как применять свертки к неструктурированным данным (к примеру графам). 

Пример данных и решаемой задачи:
![пример данных](https://habrastorage.org/webt/4m/af/zd/4mafzdmkubse90xn2vgxazge90y.png)

<cut/>

#### Существующие датасеты

Для начала - какие данные есть в открытом доступе.
* [китти](http://www.cvlibs.net/datasets/kitti/) - датасет собирался для беспилотных автомобилей. Данные с лидаров и изображения с камер установленных на крыше автомобиля. Предлагается решать задачи детекции, классификации и  отслеживания участников дорожного движения.
* [Stanford Large-Scale 3DIndoor Spaces Dataset (S3DIS)](http://buildingparser.stanford.edu/dataset.html) - размеченные сцены внутри зданий
* [ScanNet](http://www.scan-net.org/) - размеченные сцены внутри зданий
* [NYUV2](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html) - размеченные сцены внутри зданий
* [ShapeNet](https://www.shapenet.org/) - объекты разных форм
* [ModelNet40](http://modelnet.cs.princeton.edu/) - объекты разных форм
* [SHREC15](https://www.cs.cf.ac.uk/shaperetrieval/shrec15/index.html) - разные позы животных и человека

#### Особенности работы с облаками точек
Нейронные сети пришли в эту область совсем недавно. И стандартные архитектуры вроде полносвязных и сверточных сетей не применимы для решения этой задачи. Почему? Рассмотрим вначале несколько свойств 3d объекта, состоящего из множества точек.

1. Не важен порядок точек. Наш объект - это множество точек и не важно, в каком порядке мы их просматриваем. Если на изображения у каждого пикселя есть  своё место, тут мы можем спокойно перемешать точки и объект не измениться. При перестановке пикселей мы наоборот  получим абсолютно новую картинку. 
2. Существует структура между точками объекта. Они имеют связи друг с другом так же как и соседние пиксели на изображении.
3. Точки объекта инвариантны к преобразованиям. Если мы изменим систему координат, объект не изменится. То есть алгоритм должен распознавать объект в различных системах координат. 

Основную проблему для стандартных нейронных сетей создает пункт 1 - стандартные нейронные сети очень зависимы от порядкового номера признака.

А теперь разберемся, как же нейронные сети решают задачи 

#### Наиболее важные статьи за последние 3 года
Нейронных сетей, которыми пользуются в качестве основы все остальные исследователи, не так уж и много. Это три архитектуры, о которых необходимо иметь представление каждому, кто собирается работать с неструктурированными данными:
* PointNet
* PointNet++
* DGCNN

* [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)
  * что решают:  Задачи классификации и сегментации в point clouds. Первопроходцы в работе с неструктурированными данными.
  * как решают: Одна сеть с двумя головами. Модель состоит из следующих блоков:
    * сеть для определения преобразования, которое потом применится ко всем точкам 
    * преобразование, применяемое к каждой точке по отдельности (обычный персепторн)
    * maxpooling, который объединяет информацию с разных точек и создает глобальный вектор признаков для всего объекта.
    * разделение сети на две части: 
      1. сеть для классификации: глобальный вектор признаков идет на вход полносвязной сети для определения класса объекта
      2. сеть для сегментации: глобальные вектор после макс пулинга и подсчитанные признаки для каждой точки идут на вход сети, которая определяем класс для каждой точки. 
  * [код](https://github.com/charlesq34/pointnet)
    
![архитектура PointNet](https://habrastorage.org/webt/fu/pv/wi/fupvwi8uf8d2pcvxbvh9ahttf5s.png)

* PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://arxiv.org/abs/1706.02413)
  * что решают: Задачи классификации и сегментации в point clouds. Те же ребята из Стенфорда, что описали PointNet.
  * как решают: рекурсивно применяют pointNet к более мелким подоблакам, по аналогии со сверточными сетями. Это позволяет выделить локальные признаки, которые терялись.
  * [код](https://github.com/charlesq34/pointnet2)

![архитектура PointNet++](https://habrastorage.org/webt/py/pj/it/pypjitwxitebw0losh7ucvr43fu.png)
  
* [Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829)
  * что решают: Задачи классификации и сегментации в point clouds. 
  * как решают: на основе имеющихся точек строя граф: вершины - точки, ребра существуют только между k ближайшими точками. Далее определяет Edge conv - специальную свертку ребрах исходящих из текущей точки. В статье предложено несколько вариантов этой свертки. В результате они использовали следующий: для каждой точки $inline$ x_i $inline$ по все её J соседним точкам считали M признаков $inline$x_{i,m} = max_j (Relu (\theta_m * (x_i - x_j) + \phi*x_i ))$inline$. 
    Полученное значение запоминается, как новый эмбединг точки. Обращаю внимание, что здесь используются локальные и глобальные координаты как входные данные для свертки. И что данный эмбединг не зависит от порядка, в котором мы рассматриваем соседей точки.
    
    Если у нас определена свертка на графе - мы можем просто построить сверточную сеть, что здесь и cделано. Также можно заметить подсчет преобразований и применения их к каждой точке по аналогии с PointNet.
    В этой статье вы также найдете прекрасный обзор других методов решения.
    
  * [код](https://github.com/WangYueFt/dgcnn)
  
![архитектура DGCNN](https://habrastorage.org/webt/0w/lp/hm/0wlphmzbejgym-a_suxjd38tea4.png) 

#### Статьи на основе PointNet и PointNet++:
* [PointWise: An Unsupervised Point-wise Feature Learning Network](https://arxiv.org/abs/1901.04544)
 * что решают: задачу сегментации. особенность - обучение без учителя
 * как решают: для каждой точки обучают вектор эмбедингов, по которому потом и кластеризуют. 
   Основной постулат статьи - похожие объекты должны иметь похожие эмбединги (например две разные ножки стула), несмотря на их удаленность. В качестве базовой модели используют PointNet. Основное новшество - функция ошибки. Она состоит из двух частей: ошибки реконструкции и ошибки гладкости. 

   Ошибка реконструкции использует информацию о контексте точки. Её задача - чтобы точки, которые окружены одинаковым геометрическим контекстом, имели похожие эмбединги. Для её подсчета на основе вектора эмбедингов для одной точки генерируются новые точки около нее. То есть признаковое описание точки должно содержать информацию об форме объекта вокруг точки.Дальше просто смотрим, насколько сгенерированные точки выпадают из реальной формы объекта:
     $$display$$L_{reconst} = \sum_{x \in Rec(f_{i,j})} \min_{y \in Env(p_{i,j})} ||x-y||_2^2 + \sum_{y \in Env(p_{i,j})} \min_{x \in Rec(f_{i,j})} ||x-y||_2^2$$display$$

   Ошибка гладкости нужна для того, чтобы ембединги были похожими у лежащих рядом точек и непохожими у далеких точек. Тут самое прекрасное - то, что они измеряют близость не просто как норму между двумя точка в евклидовом пространстве, а считают расстояние через точки объекта. Для каждой точки выбирается одна точка из k ближайших и из k дальнейших. 
    Текущий эмбединг должен быть ближе к ближайшей минимум на некий margin, чем до дальнейшей.

* [PointCNN: Convolution On X-Transformed Points](https://papers.nips.cc/paper/7362-pointcnn-convolution-on-x-transformed-points)
  * что решают: задачу сегментации и классификации
  * как решают: реализовали новую свертку. и применяют её как в сверточной сети.
    1. Переводят координаты ближайших точек к нашей в локальные координаты. 
    2. Далее считают признаки как в pointNet 
    3. Используя локальные координаты, считают X-матрицу преобразования координат, применяют её к объединению подсчитанных признаков и изначальных, например цвет или нормаль к поверхности. Просто переводят признаки в другую систему координат. 
    4. применяют к полученным перемешанным трансформированным признакам ближайшим k точкам около нашей обычную свертку. В результате получают новый эмбединг для текущей точки. Важно отметить, что от места порядка точек здесь много зависит и после их перемешивания результат будет другим.
  * [код](https://github.com/yangyanli/PointCNN)

![архитектура PointCNN](https://habrastorage.org/webt/q5/j6/vb/q5j6vblmeheg-oq0lx5efjicf0w.png)
![архитектура PointCNN](https://habrastorage.org/webt/q9/zq/pg/q9zqpgmuc-86hnxedvjfaotzkrq.png)
![архитектура PointCNN](https://habrastorage.org/webt/gl/vy/w8/glvyw878vel074w3bt8cq4vgsok.png)

    
* [SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation](https://arxiv.org/abs/1711.08588)
  * что решают: задачу сегментации
  * как решают: как и в PointWise тут самое интересное в подсчете ошибки. В качестве основы - PointNet++, вначале считаем вектор признаков и класс для каждой точки в отдельности по аналогии с PointNet++.
   Далее на основе этих точек считаем 3 матрицы (похожести, уверенности и сегментации).
   Ошибка обучения будет суммой из 3ех ошибок, подсчитанных по соответствуюзим матрицам: $$display$$L = L_{SIM} + L_{CF} + L_{SEM}$$display$$

   Пусть N - количество точек    
   Матрица похожести - квадратная, размером N*N. Элемент на пересечении iой строки и jго столбца говорит о том, принадлежат ли эти точки одному объекту или нет. Точки, принадлежащие одному объекту, должны иметь похожие вектора признаков. Элементы матрицы могут принимать одно из 3ех значений: точки i и j  принадлежат одному объекту, точки принадлежат одному классу объектов, но разным объектам (и то и то стул, но стулья разные), или это вообще точки из объектов разных классов.

   Ошибка похожести, которая считается по этой матрице, зависит от истинного значения, которое должно было быть в ней и подсчитанных признаков.
   
![Ошибка похожести](https://habrastorage.org/webt/s2/wl/uj/s2wlujchehww4peistxr6_l79go.png)


   Матрица уверенности - это вектор длинны N. Для каждой точки мы считаем пересечение деленное на объединение (intersection over union - IoU) между множеством точек, которые принадлежат объекту согласно работе нашего алгоритма, и множеством точек, которые в реальности принадлежат объекту с нашей точкой. Ошибка - просто L2 норма между правдой и подсчитанной матрицей. То есть сеть пытается предсказать, насколько она уверена в предсказание класса для точек объекта.
   
   Матрица сегментации имеет размер - N * количество классов. Ошибка здесь считается как кроссэнтропия в  задаче многоклассовой классификации.
   * [код](https://github.com/laughtervv/SGPN)

![архитектура SGPN](https://habrastorage.org/webt/m8/6r/ra/m86rrazo6hfvzrufhy5uyihgnui.png)
    
* [Know What Your Neighbors Do:3D Semantic Segmentation of Point Clouds](https://arxiv.org/abs/1810.01151)
  * что решают: задачу сегментации
  * как решают: Вначале долго считают признаки, сложнее чем в PointNet, с кучей residual связей, и сумм, но в общем и целом - то же самое. Небольшое отличие - они параллельнно считают признаки для каждой точки в глобальных и локальных координатах. Для каждой точки, предсказывает к какому классу точка принадлежит.
     
   Основное отличие тут - это снова подсчет ошибки. Это не стандартная кроссэнтропия, а сумма двух ошибок: 
     1. pairwise distance loss - точки из одного класса должны быть ближе чем $\tau_{near}$ и точки из разных классов должны быть дольше чем $\tau_{far}$. 
     2.  centroid loss - точки из одного класса должны быть близки друг к другу
     
![centroid loss](https://habrastorage.org/webt/xu/4j/ye/xu4jyel_d_sf9biwtupxtlultzu.png)

        
        
#### статьи на основе DGCNN:
* [Linked Dynamic Graph CNN: Learning on Point Cloud via Linking Hierarchical Featurese](https://arxiv.org/abs/1904.10014)
  * что решают: Задачи классификации и сегментации в point clouds. 
  * как решают: использовали предыдущую архитектуру и добавили в неё residual connections

![архитектура Linked DGCNN](https://habrastorage.org/webt/ov/zk/h7/ovzkh78zz0cnczzdp0notx8u6ea.png)

* [SpiderCNN: Deep Learning on Point Sets with Parameterized Convolutional Filters](https://arxiv.org/abs/1803.11527)
  * что решают: задачи сегментации и классификации
  * как решают: по аналогии с DGCNN применяют аналог сверток к k ближайшим точкам около текущей, предварительно отсортировав. Основное отличие - вместо обычных координат на вход свертке подается подобие разложения функции тейлора $$display$$ f_{w^T}(x,y,z) = w_0^T+w_1^Tx+w_2^Ty+w_3^Tz+w_4^Txy+w_5^Tyz+w_6^Txz+w_7^Txyz$$display$$.
  * [код](https://github.com/xyf513/SpiderCNN)

![архитектура SpiderCNN](https://habrastorage.org/webt/i4/by/ri/i4byrilcta4j39uxxevtacr9q1g.png)