#### Введение

Некоторое время назад мне потребовалось решить задачу классификации и сегментации точек в Point Cloud (данные, полученные с лидаров). Поиски какого-то общего обзора существующих методов оказались неуспешными, поэтому пришлось собирать информацию самостоятельно. Результат вы можете видеть: здесь собраны наиболее важные и интересные (по моему мнению) статьи за последние несколько лет. 

Эта статья будет полезна тем, кто хорошо знаком с нейронными сетями, в особенности со сверточными, и хочет понять, как применять свертки к неструктурированным данным (к примеру графам). 

Пример данных и решаемой задачи:
![пример данных](https://habrastorage.org/webt/4m/af/zd/4mafzdmkubse90xn2vgxazge90y.png)

<cut/>

#### Существующие датасеты

Сейчас в открытом доступе есть следующие датасеты по этой теме:

* [китти](http://www.cvlibs.net/datasets/kitti/) - датасет собирался для беспилотных автомобилей. Данные с лидаров и изображения с камер установленных на крыше автомобиля. Предлагается решать задачи детекции, классификации и  отслеживания участников дорожного движения.
* [Stanford Large-Scale 3DIndoor Spaces Dataset (S3DIS)](http://buildingparser.stanford.edu/dataset.html) - размеченные сцены внутри зданий
* [ScanNet](http://www.scan-net.org/) - размеченные сцены внутри зданий
* [NYUV2](https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html) - размеченные сцены внутри зданий
* [ShapeNet](https://www.shapenet.org/) - объекты разных форм
* [ModelNet40](http://modelnet.cs.princeton.edu/) - объекты разных форм
* [SHREC15](https://www.cs.cf.ac.uk/shaperetrieval/shrec15/index.html) - разные позы животных и человека

#### Особенности работы с облаками точек
Нейронные сети пришли в эту область совсем недавно. И стандартные архитектуры вроде полносвязных и сверточных сетей не применимы для решения этой задачи. Почему? 

Потому что нам не важен порядок точек. Наш объект - это множество точек и не важно, в каком порядке мы их просматриваем. Если на изображения у каждого пикселя есть  своё место, тут мы можем спокойно перемешать точки и объект не измениться. Результат работы нейронных сетей, наоборот, зависит от местоположения данных. Если мы перемешаем пиксели на изображение, мы получим новый объект.

А теперь разберемся, как же нейронные сети решают задачи 

#### Наиболее важные статьи
Нейронных сетей, которыми пользуются в качестве основы все остальные исследователи, не так уж и много. Это три архитектуры, о которых необходимо иметь представление каждому, кто собирается работать с неструктурированными данными:
* PointNet
* PointNet++
* DGCNN

Теперь рассмотрим каждую поподробнее.

* [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)
  * что решают:  Задачи классификации и сегментации в point clouds. Первопроходцы в работе с неструктурированными данными.
  * как решают: Одна сеть с двумя головами. Модель состоит из следующих блоков:
    * сеть для определения преобразования, которое потом применится ко всем точкам 
      * преобразование, применяемое к каждой точке по отдельности (обычный персепторн)
      * maxpooling, который объединяет информацию с разных точек и создает глобальный вектор признаков для всего объекта.
      * разделение сети на две части: 
        1. сеть для классификации: глобальный вектор признаков идет на вход полносвязной сети для определения класса объекта
        2. сеть для сегментации: глобальный вектор признаков и подсчитанные признаки для каждой точки идут на вход сети, которая определяет класс для каждой точки. 
  * [код](https://github.com/charlesq34/pointnet)
    
![архитектура PointNet](https://habrastorage.org/webt/fu/pv/wi/fupvwi8uf8d2pcvxbvh9ahttf5s.png)

* PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://arxiv.org/abs/1706.02413)
  * что решают: Задачи классификации и сегментации в point clouds. Те же ребята из Стенфорда, что описали PointNet.
  * как решают: рекурсивно применяют pointNet к более мелким подоблакам, по аналогии со сверточными сетями. То есть делят пространство кубы, к каждому применяют PointNet, потом из этих кубов составляются новые кубы. Это позволяет выделить локальные признаки, которые теряла предыдущая версия сети.
  * [код](https://github.com/charlesq34/pointnet2)

![архитектура PointNet++](https://habrastorage.org/webt/py/pj/it/pypjitwxitebw0losh7ucvr43fu.png)
  
* [Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829)
  * что решают: Задачи классификации и сегментации в point clouds. 
  * как решают: на основе имеющихся точек строят граф: вершины - точки, ребра существуют только между текущей точкой и k ближайшими к ней точками. Далее определяют Edge conv - специальную свертку на ребрах исходящих из текущей точки. В статье предложено несколько вариантов этой свертки. В результате использовался следующий: для каждой точки $inline$ x_i $inline$ по всем её J соседним точкам считали M признаков $inline$x_{i,m} = max_j (Relu (\theta_m * (x_i - x_j) + \phi*x_i ))$inline$. 
    Полученное значение запоминается, как новый эмбединг точки. Обращаю внимание, что здесь используются локальные (x_j - x_i) и глобальные (x_j) координаты как входные данные для свертки. И что данный эмбединг не зависит от порядка, в котором мы рассматриваем соседей точки.    
    Если у нас определена свертка на графе - мы можем просто построить сверточную сеть, что здесь и cделано. Также можно заметить подсчет преобразований и применения их к каждой точке по аналогии с PointNet.
    В этой статье вы также найдете прекрасный обзор других методов решения.
    
  * [код](https://github.com/WangYueFt/dgcnn)
  
![архитектура DGCNN](https://habrastorage.org/webt/0w/lp/hm/0wlphmzbejgym-a_suxjd38tea4.png) 

#### Статьи на основе PointNet и PointNet++:
* [PointWise: An Unsupervised Point-wise Feature Learning Network](https://arxiv.org/abs/1901.04544)
 * что решают: Задачу сегментации в point clouds. Особенность работы - обучение без учителя
 * как решают: для каждой точки обучают вектор эмбедингов, по которому потом и кластеризуют. 
   Основной постулат статьи - похожие объекты должны иметь похожие эмбединги (например две разные ножки стула), несмотря на их удаленность. В качестве базовой модели используют PointNet. Основное новшество - функция ошибки. Она состоит из двух частей: ошибки реконструкции и ошибки гладкости. 
   Ошибка реконструкции использует информацию о контексте точки. Её задача - чтобы точки, которые окружены одинаковым геометрическим контекстом, имели похожие эмбединги. Для её подсчета на основе вектора эмбедингов для одной точки генерируются новые точки около нее. То есть признаковое описание точки должно содержать информацию об форме объекта вокруг точки. Дальше просто смотрим, насколько сгенерированные точки выпадают из реальной формы объекта.
   Ошибка гладкости нужна для того, чтобы ембединги были похожими у лежащих рядом точек и непохожими у далеких точек. Тут самое прекрасное - то, что они измеряют близость не просто как норму между двумя точка в евклидовом пространстве, а считают расстояние через точки объекта. Для каждой точки выбирается одна точка из k ближайших и из k дальнейших. 
   Текущий эмбединг должен быть ближе к ближайшей минимум на некий margin, чем до дальнейшей.
    
* [SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation](https://arxiv.org/abs/1711.08588)
  * что решают: Задачу сегментации в point clouds.
  * как решают: как и в PointWise тут самое интересное в подсчете ошибки. В качестве основы - PointNet++, вначале считаем вектор признаков и класс для каждой точки в отдельности по аналогии с PointNet++.
    Далее на основе признаков считаем 3 матрицы (похожести, уверенности и сегментации).
    Ошибка обучения будет суммой из 3ех ошибок, подсчитанных по соответствуюзим матрицам: $$display$$L = L_{SIM} + L_{CF} + L_{SEM}$$display$$
    Пусть N - количество точек    
    Матрица похожести - квадратная, размером N\*N. Элемент на пересечении iой строки и jго столбца говорит о том, принадлежат ли эти точки одному объекту или нет. Точки, принадлежащие одному объекту, должны иметь похожие вектора признаков. Элементы матрицы могут принимать одно из 3ех значений: точки i и j  принадлежат одному объекту, точки принадлежат одному классу объектов, но разным объектам (и то и то стул, но стулья разные), или это вообще точки из объектов разных классов.
    Ошибка похожести, которая считается по этой матрице, зависит от истинного значения, которое должно было быть в ней и подсчитанных признаков.
    ![Ошибка похожести](https://habrastorage.org/webt/s2/wl/uj/s2wlujchehww4peistxr6_l79go.png)
    Матрица уверенности - это вектор длинны N. Для каждой точки мы считаем пересечение деленное на объединение (intersection over union - IoU) между множеством точек, которые принадлежат объекту согласно работе нашего алгоритма, и множеством точек, которые в реальности принадлежат объекту с нашей точкой. Ошибка - просто L2 норма между правдой и подсчитанной матрицей. То есть сеть пытается предсказать, насколько она уверена в предсказание класса для точек объекта.
    Матрица сегментации имеет размер - N * количество классов. Ошибка здесь считается как кроссэнтропия в  задаче многоклассовой классификации.
  * [код](https://github.com/laughtervv/SGPN)

![архитектура SGPN](https://habrastorage.org/webt/m8/6r/ra/m86rrazo6hfvzrufhy5uyihgnui.png)
    
* [Know What Your Neighbors Do:3D Semantic Segmentation of Point Clouds](https://arxiv.org/abs/1810.01151)
  * что решают: Задачу сегментации в point clouds.
  * как решают: Вначале долго считают признаки, сложнее чем в PointNet, с кучей residual связей, и сумм, но в общем и целом - то же самое. Небольшое отличие - они считают признаки для каждой точки в глобальных и локальных координатах.
    Основное отличие тут - это снова подсчет ошибки. Это не стандартная кроссэнтропия, а сумма двух ошибок: 
    1. pairwise distance loss - точки из одного объекта должны быть ближе чем $inline$\tau_{near}$inline$ и точки из разных объектов должны быть дольше чем $inline$\tau_{far}$inline$. 
        ![pairwise distance loss](https://habrastorage.org/webt/xu/4j/ye/xu4jyel_d_sf9biwtupxtlultzu.png)
    2. centroid loss - точки из одного объекта должны быть близки друг к другу

#### статьи на основе DGCNN:

Так как DGCNN была опубликована недавно (2018), то статей, основанных на этой архитектуре немного. Я хочу обратить ваше внимание только на одну.

* [Linked Dynamic Graph CNN: Learning on Point Cloud via Linking Hierarchical Featurese](https://arxiv.org/abs/1904.10014)
  * что решают: Задачи классификации и сегментации в point clouds. 
  * как решают: использовали предыдущую архитектуру и добавили в неё residual connections

![архитектура Linked DGCNN](https://habrastorage.org/webt/ov/zk/h7/ovzkh78zz0cnczzdp0notx8u6ea.png)

#### Заключение

Здесь вы могли найти краткую информацию о современных методах решения задач классификации и сегментации в Point Clouds. Существуют две основных модели (PointNet++, DGCNN), модификации которых сейчас используют для решения этих задач. Чаще всего для модификации изменяют функцию потерь, но также усложняют эти архитектуры, добавляя слои и связи. 
